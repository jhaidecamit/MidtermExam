{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: torch in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (2.3.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting flask\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from flask) (3.0.3)\n",
      "Collecting itsdangerous>=2.1.2 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from flask)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jhaide\\downloads\\chatbot jotter-o\\.env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.7/101.7 kB ? eta 0:00:00\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: itsdangerous, blinker, nltk, flask\n",
      "Successfully installed blinker-1.8.2 flask-3.0.3 itsdangerous-2.2.0 nltk-3.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch nltk flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      User Input               Intent  \\\n",
      "0            \"Book a flight to Manila on Monday\"       Flight Booking   \n",
      "1          \"I want to cancel my flight to Davao\"  Flight Cancellation   \n",
      "2  \"Can I change my flight from Cebu to Manila?\"        Change Flight   \n",
      "3                 \"How much baggage can I take?\"      Baggage Inquiry   \n",
      "4                        \"Is my flight on time?\"  Check Flight Status   \n",
      "\n",
      "                                        Entities  \n",
      "0  \"{'destination': 'Manila', 'date': 'Monday'}\"  \n",
      "1                     \"{'destination': 'Davao'}\"  \n",
      "2  \"{'origin': 'Cebu', 'destination': 'Manila'}\"  \n",
      "3                                           \"{}\"  \n",
      "4                                           \"{}\"  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Intents.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_model = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      User Input               Intent  \\\n",
      "0            \"Book a flight to Manila on Monday\"       Flight Booking   \n",
      "1          \"I want to cancel my flight to Davao\"  Flight Cancellation   \n",
      "2  \"Can I change my flight from Cebu to Manila?\"        Change Flight   \n",
      "3                 \"How much baggage can I take?\"      Baggage Inquiry   \n",
      "4                        \"Is my flight on time?\"  Check Flight Status   \n",
      "\n",
      "                                        Entities  \n",
      "0  \"{'destination': 'Manila', 'date': 'Monday'}\"  \n",
      "1                     \"{'destination': 'Davao'}\"  \n",
      "2  \"{'origin': 'Cebu', 'destination': 'Manila'}\"  \n",
      "3                                           \"{}\"  \n",
      "4                                           \"{}\"  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Intents.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [{'entity': 'I-LOC', 'score': 0.9996762, 'index': 5, 'word': 'Paris', 'start': 17, 'end': 22}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "\n",
    "user_input = \"Book a flight to Paris for tomorrow\"\n",
    "\n",
    "\n",
    "entities = ner(user_input)\n",
    "print(\"Entities:\", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_labels = {intent: idx for idx, intent in enumerate(data['Intent'].unique())}\n",
    "data['Label'] = data['Intent'].map(intent_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(df):\n",
    "    return tokenizer(list(df['User Input']), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "train_encodings = tokenize_data(train_data)\n",
    "test_encodings = tokenize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IntentDataset(train_encodings, train_data['Label'].tolist())\n",
    "test_dataset = IntentDataset(test_encodings, test_data['Label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(intent_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jhaide\\Downloads\\ChatBot Jotter-O\\.env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhaide\\AppData\\Local\\Temp\\ipykernel_19836\\2198959674.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished.\n",
      "Epoch 2 finished.\n",
      "Epoch 3 finished.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(3):  # Number of training epochs\n",
    "    for batch in DataLoader(train_dataset, batch_size=8, shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1} finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I need to fly to Singapore from the Philippines next week\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [{'entity': 'I-LOC', 'score': 0.99986756, 'index': 6, 'word': 'Singapore', 'start': 17, 'end': 26}, {'entity': 'I-LOC', 'score': 0.99985933, 'index': 9, 'word': 'Philippines', 'start': 36, 'end': 47}]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(user_input, return_tensors='pt', padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    predicted_intent = [intent for intent, idx in intent_labels.items() if idx == predicted_label][0]\n",
    "\n",
    "\n",
    "entities = ner_pipeline(user_input)\n",
    "\n",
    "\n",
    "print(\"Entities:\", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: You can book a flight to Manila through our website or mobile app.\n",
      "Thank you for your feedback!\n",
      "User Feedback:  None\n",
      "Adjusted Response:  Thank you for the feedback! I'm glad you found my response helpful.\n"
     ]
    }
   ],
   "source": [
    "feedback = []\n",
    "\n",
    "def get_user_feedback():\n",
    "    rating = input(\"On a scale of 1 to 5, how would you rate my response? \")\n",
    "    try:\n",
    "        rating = int(rating)\n",
    "        if 1 <= rating <= 5:\n",
    "            feedback.append(rating)\n",
    "            print(\"Thank you for your feedback!\")\n",
    "        else:\n",
    "            print(\"Please provide a rating between 1 and 5.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number between 1 and 5.\")\n",
    "\n",
    "def adjust_response():\n",
    "    if not feedback:\n",
    "        return \"I have not received any feedback yet.\"\n",
    "    avg_feedback = sum(feedback) / len(feedback)\n",
    "    if avg_feedback < 3:\n",
    "        return \"Sorry, Iâ€™ll improve my response next time.\"\n",
    "    else:\n",
    "        return \"Thank you for the feedback! I'm glad you found my response helpful.\"\n",
    "\n",
    "user_input = \"Can you help me book a flight to Manila?\"\n",
    "\n",
    "response = \"You can book a flight to Manila through our website or mobile app.\"\n",
    "\n",
    "print(\"Chatbot:\", response)\n",
    "\n",
    "\n",
    "print(\"User Feedback: \", get_user_feedback())\n",
    "\n",
    "\n",
    "adjusted_response = adjust_response()\n",
    "print(\"Adjusted Response: \", adjusted_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
